% Chapter 3

\chapter{Iterative Techniques for Mixed-Integer Linear Programming Problems} % Main chapter title

\label{Chapter3} % For referencing the chapter elsewhere, use \ref{Chapter2} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
As we stated in previous chapters, quantum computers are not mature enough to solve real-world problems. For instance, the embedding of a QUBO problem into the architecture of a quantum annealer imposes an important constraint in the number of variables our problem can have. For this reason, a \textit{hybrid quantum-classical} (HQC) approach is currently the best method one can use to tackle large-scale problems, by combining quantum and classical solvers.\\\\
The aim of HQC approaches is to decompose a problem into a \textit{sub-problem(s)} (SP(s)) and a \textit{master problem} (MP), with the hope that one of these problems is suitable for a quantum computer. On the one hand, a quantum annealer receives a QUBO problem or a problem that can be cast into it. On the other, the other problems are solved by the classical solver using cutting-edge algorithms. The MP and SP(s) are solved iteratively until a given stopping criterion is satisfied. \\\\
There are classical systematic approaches that always converge for convex functions, such as the Benders' decomposition algorithm\,\cite{Pereira1991}, while other heuristic approaches do not guarantee the optimal solution, but they require less computational resources to find a sub-optimal solution by exploring the configuration space according to some criteria.\\\\
In this chapter, we describe the general formulation of a mixed-integer linear programming problem, then we present the most relevant results of dual dynamic programming theory, which is the underlying theory of problem decomposition. Finally, we show a quantum-classical Benders' decomposition protocol\,\cite{Zhao2021HybridProgramming}, a heuristic quantum-classical protocol\,\cite{Ding2019ImplementationDesign} and another version inspired on it.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MILP
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Mixed-Integer Linear Programming}
In the present work, we are interested in mixed-integer linear programming (MILP) problems because they appear in a wide range of real-world applications and they are the corresponding mathematical formulation of TEP problems. More precisely, TEP problems contain real variables but these variables are often converted into integer values to solve the problem.\\\\
The general mathematical formulation of MILP problems is
\begin{mini!}[2]
	{\mathbf{x},\mathbf{y}}{f(\mathbf{x}, \mathbf{y})}{\label{eq: MILP}}{}{\left[f: \mathbb{R}^{n}\times \mathbb{Z}^{m} \rightarrow \mathbb{R}\right]}
	\addConstraint{h(\mathbf{x},\mathbf{y})}{=\textbf{0}\quad}{\left[h: \mathbb{R}^{n}\times \mathbb{Z}^{m} \rightarrow \mathbb{R}^{q}\right]}
	\addConstraint{g(\mathbf{x})}{\leq \textbf{0}\quad}{\left[g: \mathbb{Z}^{n} \rightarrow \mathbb{R}^{p}\right],}
\end{mini!}
where $q$ and $p$ are the number of equality and inequality constraints and $(\mathbf{x},\mathbf{y})$ are the real and integer variables, respectively.\\\\
TEP problems scale badly as the problem size grows. Thus, large problems cannot be solved at the desired resolution by nowadays classical computers with solvers such as Gurobi\,\cite{gurobi}, CPLEX\,\cite{cplex2009v12} or cbc\,\cite{cbc}. There are already benchmarks comparing classical solvers and quantum annealers for energy problems where even the fastest of these solvers -- Gurobi -- cannot find the optimal solution in a fixed run-time, see Ref.\,\cite{Fernandez-Campoamor2021CommunityAnnealing}. \\\\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Classical Benders Decomposition
%%%%%%%%%%%%%
\section{Classical Benders' Decomposition}
The main idea behind classical \textit{Benders' decomposition} (BD) -- also known as \textit{dual dynamic programming} (DDP) -- is to decompose the primal problem into a master problem and a sub-problem(s) once the complicated variables are detected. In the following sections, we introduce the most relevant results of dual dynamic programming. For a deeper understanding see Ref.\,\cite{bierlaire2018}.
%%%%%%%%%%%%%
\subsection{Complicated Variables}
We can consider a decision variable to be complicated if the decision variable is involved in most of the constraints or the decision variable produces non-convex optimization problems. 
\begin{definition}{}{Complicated variables}
Complicated variables are those that allow us to split the original problem into sub-problem(s) when they are fixed. These variables appear in constraints in such a way that the problem cannot be decomposed if they are not fixed. These type of constraints are known as linking constraints. 
\end{definition}
After splitting the original problem, the master problem is a relaxed version of the original problem. The global minimum is guaranteed if and only if the objective function as a function of the complicated variables is a convex envelope.\\\\
The BD method is used to decompose the general problem \eqref{eq: MILP} into an MP with integer variables and an SP so that a clever rearrangement of the variables allows us to fix the complicated variables of the MP -- once the MP is solved -- and send these complicated variables as fixed for the sub-problem. This process is performed iteratively until a stopping criterion is satisfied. The convergence of BD guarantees that we can satisfy an arbitrary threshold value after a number of iterations\,\cite{Sahinidis1991BDConvergence}. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dual Dynamic Programming}
Suppose that an electricity market has to sell its energy production to different customers. However, the maximum amount of energy per customer is fixed to $10$ units of energy where each unit of energy cost $1$\$. The electricity company decides to relax the constraints allowing customer Bob to buy more than $10$ units of energy but paying $2$\$ for each extra unit of energy. Bob decides to buy extra units of energy because with one unit of energy he produces a chip that he sells for $3$\$. Then, Bob buys every extra energy unit he can, getting a profit of $1$\$ for each extra unit of energy. The electricity market notices that Bob is buying too much energy and it cannot provide the required energy to other customers, paying a fine because of that. In order to relax the constraints but at the same time be able to satisfy the demand of other customers, the electricity market decides to increase the price of the extra unit of energy to $3$\$. Now, the current price of extra unit of energy implies that Bob does not get profit so he is no longer interested in buying extra units of energy. In other words, Bob has no interest in violating the constraint, which he could do because it has been relaxed.\\\\
Notice that we have two points of view when solving combinatorial optimization problems. We can adopt either the customer's viewpoint, who wants to solve the optimization problem, or the market's, which defines the constraints and prices.\\\\
We can relax the primal problem\,\eqref{eq: MILP} by associating a penalty to each of its constraints,
\begin{equation}
    \lambda\in\mathbb{R}^{q}\,\, \textrm{and} \, \mu\in\mathbb{R}^{p},
\end{equation}
also known as Lagrange multipliers. Then the Lagrangian of the primal problem is
\begin{equation}
    \mathcal{L}(\mathbf{x},\mathbf{y}, \lambda, \mu) = f(\mathbf{x}, \mathbf{y}) + \lambda^{\intercal}h(\mathbf{x},\mathbf{y}) + \mu^{\intercal}g(\mathbf{x})\ .
\end{equation}
The Lagrangian allows us to reformulate the problem by augmenting the objective function with a set of constraint functions weighted by the Lagrange multipliers, so that our new problem has zero constraints.
\begin{definition}{Dual function}{}
The dual function, $q: \left[\mathbb{R}^{q+p}\rightarrow\mathbb{R}\right]$, maps the set of parameters $\lambda$ and $\mu$ to a minimization problem
\begin{equation}
    q(\lambda, \mu) = \min_{\mathbf{x}, \mathbf{y}}\mathcal{L}(\mathbf{x},\mathbf{y}, \lambda, \mu)\ ,
\end{equation}
where $q$ and $p$ are the number of equality and inequality constraints and
\begin{equation}
    \lambda\in\mathbb{R}^{q}\,\, \textrm{and}\, \mu\in\mathbb{R}^{p}\ ,
\end{equation}
are the penalty parameters.
\end{definition}
Notice that the dual function is an unconstrained problem because all the constraints have been moved into the Lagrangian.
Considering the MILP problem \eqref{eq: MILP}, the inequality constraint $g(\mathbf{x})\leq \mathbf{0}$ is violated if $g(\mathbf{x})>\mathbf{0}$. To take into account this in the cost function we need to introduce a positive cost, so $\mu^{\intercal}g(\mathbf{x})>0$ which implies $\mu$ has positive coefficients, that is
\begin{equation}
    \mu \geq \mathbf{0}\ .
\end{equation}
\begin{theorem}{}{}
The dual of a linear optimization problem is another linear optimization problem.
\end{theorem}
\begin{theorem}{}{}
The dual of the dual is the primal.
\end{theorem}
\begin{theorem}{}{}
Suppose that $(\mathbf{x}^{*}, \mathbf{y}^{*})$ is an optimal solution -- so it is feasible -- of the primal. Then,
\begin{equation}
    q(\lambda, \mu) \leq f(\mathbf{x}^{*},\mathbf{y}^{*})
\end{equation}
is a lower bound of the primal problem, for
\begin{equation}
    \lambda\in\mathbb{R}^{q}\, \textrm{and}\, \mu\in\mathbb{R}^{p}\ .
\end{equation}
\end{theorem}
\begin{proof}
\begin{align}
    q(\lambda, \mu) = \min_{\mathbf{x}, \mathbf{y}} \mathcal{L}(\mathbf{x}, \mathbf{y}, \lambda, \mu) \leq \mathcal{L}(\mathbf{x}^{*}, \mathbf{y}^{*}, \lambda, \mu) = f(\mathbf{x}^{*}, \mathbf{y}^{*}) + \underbrace{\lambda^{\intercal}h(\mathbf{x}^{*}, \mathbf{y}^{*})}_{0} + \underbrace{\mu^{\intercal}g(\mathbf{x}^{*})}_{\leq 0} \leq f(\mathbf{x}^{*}, \mathbf{y}^{*})
\end{align}
\end{proof}
A feasible solution satisfies the constraints, meaning that $h(\mathbf{x}^{*}, \mathbf{y}^{*})=\mathbf{0}$ and $g(\mathbf{x}^{*}) \leq \mathbf{0}$. This implies that the dual function $q(\lambda,\mu)$ is a lower bound and the relaxed problem $f(\mathbf{x}^{*}, \mathbf{y}^{*})$ is the upper bound. Notice that if $\mu = \mathbf{0}$, then the lower bound and upper bound would have the same value. In DDP we need to optimize not only the decision variables $\mathbf{x}$ but also the penalty parameters $\mu$ and $\lambda$.
\begin{corollary}{}{}
  In particular, if $(\mathbf{x}^{*}, \mathbf{y}^{*})$ is an optimal solution of the primal and $(\mathbf{x}, \mathbf{y})$ is a feasible solution of the primal, then
  \begin{equation}
      \underbrace{q({\lambda,\mu})}_{\textrm{Lower Bound}} \leq f(\mathbf{x}^{*}, \mathbf{y}^{*}) \leq \underbrace{f(\mathbf{x}, \mathbf{y})}_{\textrm{Upper Bound}}
  \end{equation}
\end{corollary}
We want to find the best possible lower bound by solving the following optimization problem
\begin{maxi!}[2]
	{\lambda, \mu}{q(\lambda, \mu)}{\label{eq: Abstract_Dual}}{}{\left[q: \mathbb{R}^{q+p} \rightarrow \mathbb{R}\right]}
	\addConstraint{\mu}{\geq \mathbf{0}}{}
	\addConstraint{(\lambda, \mu)}{}{\in \{\lambda, \mu \,\mid\, q(\lambda, \mu)\,  \textrm{Bounded} \}\ .}
\end{maxi!}
Notice that we are choosing the penalties in such a way that the dual problem is bounded.
\begin{theorem}{Weak Duality}{}
If $(\mathbf{x}^{*}, \mathbf{y}^{*})$ is the optimal solution of the primal, and $(\lambda^{*}, \mu^{*})$ is the optimal solution of the dual, then
\begin{equation}
    q(\lambda^{*}, \mu^{*}) \leq f(\mathbf{x}^{*}, \mathbf{y}^{*})\ .
\end{equation}
This inequality holds even for non-convex problems.
\end{theorem}
The difference between the lower bound and the upper bound is known as the optimal duality gap which is always non-negative.
\begin{theorem}{Strong Duality}{}
If $(\mathbf{x}^{*}, \mathbf{y}^{*})$ is the optimal solution of a convex\footnote{There are conditions beyond convexity under which the strong duality holds. However, we are not going to discuss them in the present work.} primal problem, and $(\lambda^{*}, \mu^{*})$ is the optimal solution of its dual, then
\begin{equation}
    q(\lambda^{*}, \mu^{*}) = f(\mathbf{x}^{*}, \mathbf{y}^{*})\ .
\end{equation}
\end{theorem}
In other words, the strong duality theorem guarantees that the upper bound and lower bound are going to converge into a point for the optimal solution, see Fig.\,\ref{fig:BD_Convergence} adapted from\,\cite{Zhao2021HybridProgramming}.
\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{Figures/BD_Convergence.pdf} 
\caption{Benders' decomposition convergence for a combinatorial problem in which the strong duality theorem is satisfied. The x-axis indicates the number of iteration in the BD algorithm and y-axis indicates the value of the cost function.}
\label{fig:BD_Convergence}
\end{figure}
\begin{corollary}{}{}
If either the primal problem or the dual problem are unbounded, then both problems are unbounded.
\end{corollary}
\begin{proof}
If the primal is unbounded, then according to the weak duality theorem
\begin{equation}
    q(\lambda^{*}, \mu^{*}) \leq \infty
\end{equation}
which implies the dual problem is unbounded. Analogously, if the dual problem is unbounded, then the primal problem is unbounded too.
\end{proof}
\begin{corollary}{}{}
If there exist $\mathbf{x}^{*}, \mathbf{y}^{*},\lambda^{*}\,\textrm{and}\, \mu^{*}$ such that,
\begin{equation}
    q(\lambda^{*}, \mu^{*}) = f(\mathbf{x}^{*}, \mathbf{y}^{*})
\end{equation}
then they are optimal.
\end{corollary}
\begin{proof}
Consider a feasible solution of the primal problem, $(\mathbf{x}, \mathbf{y})$, and a feasible solution of the dual problem, $(\lambda, \mu)$, then
\begin{equation}
    f(\mathbf{x}, \mathbf{y}) \geq q(\lambda^{*}, \mu^{*}) = f(\mathbf{x}^{*}, \mathbf{y}^{*}) \geq q(\lambda, \mu)\ .
\end{equation}
\end{proof}
%%%%%%%%%%%%%%
\subsection{Karush–Kuhn–Tucker Conditions}
In this section we introduce a first-order necessary conditions for a solution of convex problems to be optimal, the \textit{Karush–Kuhn–Tucker} (KKT) conditions. For a deeper understanding see Ref.\,\cite{Boyd2004}.\\\\
Suppose we are given an LP problem, i.e., a problem with real variables $x_{i}\in\mathbf{x}$ whose functions are differentiable. Then its Lagrangian can be written as
\begin{equation}
    \mathcal{L}(\mathbf{x}, \lambda, \mu) = f(\mathbf{x}) + \lambda^{\intercal}h(\mathbf{x}) + \mu^{\intercal}g(\mathbf{x})\ .
\end{equation}
We can get the dual problem of \,\eqref{eq: MILP} by writing a set of equations from the Lagrangian and the constraints of the primal problem. The following set of equations 
\begin{align}
    \frac{\partial \mathcal{L}(\mathbf{x},\lambda, \mu)}{\partial x_{i}} &= 0, \quad  \forall x_{i} \in \mathbf{x} \\
    h(\mathbf{x}) &= \mathbf{0} \\
    \mathbf{0}\leq - g(\mathbf{x})&\perp \mu \geq \mathbf{0} 
\end{align}
are known as the KKT conditions. Notice that if the optimization problem we are minimizing does not have any constraint, then we could consider just the first equation, i.e., the partial derivatives of the Lagrangian.\\\\
MILP problems mix real and integer variables which implies they are not convex and its functions are not differentiable so that KKT conditions are no longer valid. However, if we decompose the MILP problem into an \textit{integer programming} (IP) problem and a \textit{linear programming} (LP) problem we could solve the LP using the KKT conditions and the IP with a standard solver or in our case with a quantum annealer.\\\\
From previous sections, we know that a MILP problem can be written as,
\begin{align}
    \max_{\lambda,\mu} q(\lambda,\mu) &=\max_{\lambda,\mu}\left[\min_{\mathbf{x},\mathbf{y}}\mathcal{L}(\mathbf{x}, \mathbf{y},\lambda,\mu)\right] \\
    &= \max_{\lambda,\mu}\underbrace{\left[\min_{\mathbf{x}\ , \mathbf{y}}f(\mathbf{x}, \mathbf{y}) + \lambda^{\intercal}h(\mathbf{x}\ , \mathbf{y}) + \mu^{\intercal}g(\mathbf{x})\right]}_{\textrm{MILP problem}} \ ,
\end{align}
where the outer optimization problem is a maximization over the Lagrange multipliers $\left(\lambda,\mu\right)$ and the inner optimization problem is a minimization over the primal variables $\mathbf{x}$ and $\mathbf{y}$. Notice that the inner problem is an unconstrained problem since the constraints of the original problem are already taken into account as penalties in the Lagrangian. The inner problem has integer variables so we cannot use the KKT conditions but if the integer variables are fixed, $\mathbf{y}^{*}$, then the inner problem is a LP
\begin{align}
    \max_{\lambda,\mu} q(\lambda,\mu) &=\max_{\lambda,\mu}\left[\min_{\mathbf{x}}\mathcal{L}(\mathbf{x}\ , \mathbf{y}^{*},\lambda,\mu)\right] \\
    &= \max_{\lambda,\mu}\underbrace{\left[\min_{\mathbf{x}}f(\mathbf{x}\ , \mathbf{y}^{*}) + \lambda^{\intercal}h(\mathbf{x}, \mathbf{y}^{*}) + \mu^{\intercal}g(\mathbf{x})\right]}_{\textrm{LP problem}}\ ,
\end{align}
  \vspace{6pt}
    \hrule
%%%%%%%%%%%%%%%%%%%
\subsubsection{Example: \textit{Quadratic Convex Minimization Problem}}
Consider the following optimization problem,
\begin{mini!}[2]
	{x}{f(x) = mx^{2} + nx}{}{}{\quad \left[f: \mathbb{R} \rightarrow \mathbb{R}\right]}
	\addConstraint{h(x)= ax - b }{=0}{\quad\left[h: \mathbb{R} \rightarrow \mathbb{R}\right]}\ .
\end{mini!}
The KKT conditions of this problem are
\begin{align}
    ax^{*}-b=0 \\
    2mx^{*}+n + a\lambda^{*}= 0\ .
\end{align}
The solution of this set of equations are the optimal primal and dual variables,
\begin{align}
    x^{*} &= \frac{b}{a} \\
    \lambda^{*} &= - \left(\frac{2mb}{a^{2}} + \frac{n}{a}\right)\ .
\end{align}
We can solve the problem in a different way by using the dual theory. First, reformulate the problem as an unconstrained inner minimization problem and an outer maximization problem
\begin{equation}
    \max_{\lambda}\left[\min_{x}\mathcal{L}(x,\lambda)\right]
\end{equation}
apply the KKT conditions in the inner problem,
\begin{align}
    \frac{\partial \mathcal{L}}{\partial x} &= 2mx + n + a\lambda = 0 \\
    x &= - \frac{n + a\lambda}{2m}\label{eq: xInner}.
\end{align}
Inserting $x$ in terms of $\lambda$ in the inner problem yields
\begin{equation}
    \max_{\lambda} \left[\frac{(n+a\lambda)^{2}}{4m} - \frac{n(n+a\lambda)}{2m} - \lambda\left(\frac{-a(n+a\lambda)}{2m} - b\right)\right].
\end{equation}
If we apply again the KKT conditions,
\begin{equation}
    \frac{\partial \mathcal{L}}{\partial \lambda} = \frac{a(n + a\lambda)}{2m} - \frac{na}{2m} - \frac{na}{2m} - \frac{\lambda a^{2}}{m} - b = 0
\end{equation}
we get
\begin{equation}
    \lambda = - \left(\frac{2mb}{a^{2}} + \frac{n}{a}\right).
\end{equation}
If we now insert this in Eq.\,\eqref{eq: xInner} we get the optimal solution of the primal problem.\\\\
This example shows two different ways of solving an optimization problem and how they are equivalent.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Benders' cuts}
Consider the following two-variable MILP problem,
\begin{mini!}[2]
	{x,y}{f(x,y) = mx + ny}{}{}{\quad \left[f: \mathbb{R} \times \mathbb{Z}  \rightarrow \mathbb{R}\right]}
	\addConstraint{h(x,y)= ax - by }{=0}{}{\label{cons:ExLink}}
	\addConstraint{g(x)=cx}{\leq 0}{}
    \addConstraint{x}{\geq 0}{}
    \addConstraint{y}{\in \{0,1\},}{}
\end{mini!}
where $a,b,c,m,n \in \mathbb{R}$, Eq.\,\eqref{cons:ExLink} is a linking constraint and the integer variable is binary. Fixing the complicated variable to a feasible value $y^{*}$ would allow us to split the original problem into an SP which is an LP:
\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Slave problem]
\begin{mini!}[2]
	{x}{\alpha \equiv mx}{}{}{}
	\addConstraint{h(x,y^{*})= ax - by^{*} }{=0}{\quad :\lambda}{}
	\addConstraint{g(x)=cx}{\leq 0}{\quad :\Pi}
    \addConstraint{x}{\geq 0}{\quad :\mu.}
\end{mini!}
\end{tcolorbox}
We can write the problem as
\begin{equation}
    \max_{\lambda,\mu}\left(\min_{x}\mathcal{L}(x,y^{*},\lambda,\Pi,\mu)\right)
\end{equation}
and using the KKT conditions in the inner optimization problem yields its dual optimization problem
\begin{maxi!}[2]
	{\lambda,\Pi,\mu}{-by^{*}\lambda}{}{}{}
	\addConstraint{\frac{\partial \mathcal{L}}{\partial x}}{= m + a\lambda + c\Pi - \mu = 0}{}
\end{maxi!}
Since the objective function only has $\lambda$ and not $\Pi$ and $\mu$ we can re-write the previous problem as an inequality by dropping the $(\Pi,\mu)$ Lagrange multipliers
\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Dual formulation of slave problem]
\begin{maxi!}[2]
	{\lambda}{-by^{*}\lambda}{}{}{}
	\addConstraint{m + a\lambda}{\geq 0}{}
\end{maxi!}
\end{tcolorbox}
The resolution of the dual problem leads to the candidate values $x^{*}$ and $\lambda^{*}$.\\
On the other hand, the MP, which is an IP, is given by
\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Master problem]
\begin{mini!}[2]
	{y, \alpha}{\underline{z} = ny + \alpha}{}{}{}
	\addConstraint{\alpha}{\geq \alpha_{\textrm{down}}}{}
    \addConstraint{\alpha}{\geq \underbrace{\lambda \left(- by\right)}_{\textrm{Benders' cuts}}}{}
    \addConstraint{y}{\in\{0,1\}.}{}
\end{mini!}
\end{tcolorbox}
where $\alpha_{\text{down}}$ is a lower bound for $\alpha$ that we must fix so that the problem is bounded.
\begin{tcolorbox}[colback=black!5!white,colframe=black!75!black,title=Strong Duality condition]
For lineal problems it is guaranteed that
\begin{equation}
    mx^{*} + ny^{*} =-by^{*}\lambda^{*}
\end{equation}
for the optimal values $x^{*},y^{*}$ and $\lambda^{*}$.
\end{tcolorbox}
 Notice that this process can be repeated, i.e., we can add an optimal cut per constraint in every iteration by cutting back the configuration space. The iterative process is known as Benders' decomposition and we provide an example of it in Ch.\,\ref{Chapter4}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% QA + SA
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Hybrid quantum-classical algorithms}
In Appxendix\,\ref{AppendixB}, we show the foundations of \textit{simulated annealing} (SA) and solve a travelling salesman problem to illustrate it. A simulated annealing algorithm does not guarantee an optimal solution but the results we can get with a clever annealing schedule can be good enough in accuracy and time. The same applies to a quantum annealing algorithm. In this section, we show how the decomposition of a QUBO problem allows us to use both quantum and classical solvers, where the classical solvers relax the original problem so that it can be tackled by the quantum solver.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Quantum Benders' Decomposition}
The main idea behind the quantum Benders approach is to use the quantum annealer to solve either the primal problem or the dual problem. We are interested in solving the primal problem, also known as master problem, with a quantum annealer. 
%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Heuristic Protocols}
As stated before, heuristic approaches do not guarantee to arrive at the optimal solution. However, these methods explore the configuration space in such a way that we do not get stuck in a local minimum. For a limited amount of computational resources and time, the solution that a heuristic approach can achieve is sub-optimal. Generally, these methods are better than a brute-force method when the problem is large enough so that there are no computational resources that are able to provide the optimal solution.
\subsubsection{SA-QA Protocol}
We present a hybrid quantum-classical algorithm protocol based on combining SA and QA\,\cite{Ding2019ImplementationDesign} to solve the MP and SP(s), respectively. Figure\,\ref{fig:SA_QAProtocol} shows a graphical representation of the SA-QA protocol, which we describe in more detail below. 
\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{Figures/SAQAProtocol.pdf} 
\caption{SA-QA scheme. See main text for details on this protocol.}
\label{fig:SA_QAProtocol}
\end{figure}
\begin{enumerate}
    \item Set the upper and lower bound of the problem -- so that we avoid dealing with unbounded problems -- and initialize a configuration for the problem, i.e., annealing schedule, initial and final temperature, and a selection criterion.
    \item Randomly generate a new configuration by changing the values of the binary variables according to a neighboring function that generates a new configuration in one of these ways:
    \begin{enumerate}
        \item Randomly pick a binary variable with value 1 and set it to 0.
        \item Randomly pick a binary variable with value 0 and set it to 1.
        \item Randomly pick two binary variables with different values and swap them.
    \end{enumerate}
    \item Given the new configuration, solve the sub-problem(s) -- dual problems -- with a quantum annealing algorithm.
    \item Apply the selection criterion to keep or discard the current configuration.
    \item If the selection criterion is not satisfied, repeat steps 2 to 4 until an iteration index is equal to the value set in step 1, then decrease the temperature and reset the iteration index. If the selection criterion is satisfied, the protocol outputs the current cost function value and its solution $\mathbf{x}$.
\end{enumerate}
Notice that the algorithm solves the master problem with a simulated annealing algorithm in a classical solver and then the sub-problem(s) -- dual problems -- with the quantum computer, more precisely with a quantum annealer. For this reason, the sub-problem(s) must have binary constraints or low integer values if we do not want to deal with discretization errors or adding a big set of slack variables.\\\\
In order to apply both simulated and quantum annealing to problems in which the master problem contains most of the binary and integer variables -- as is the case with the TEP problem --, we have to reconsider or adapt the previous scheme.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% QA-SA Protocol
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{QA-SA Protocol}
 As stated before, our sub-problem(s) has real constraints which implies it is not a clever approach to solve them with a quantum annealer. For this reason, we reverse the original protocol so that the quantum annealer tackles the master problem in which the binary and integer decision variables appear and the classical solver tackles the sub-problem(s). A scheme of the new protocol is shown in Figure\,\ref{fig:QA_SAProtocol}.\\\\
In order to explain the protocol in accordance to what has been shown in the previous section we use the same notation $f(\mathbf{x}, \mathbf{y})$ to describe the upper bound of the primal problem and $q(\lambda,\mu)$ to describe the lower bound, where $(\lambda,\mu)$ represents the penalties of our problem, that is, the Lagrange multipliers, and $\mathbf{x},\mathbf{y}$ represent the decision variables. We are showing a heuristic approach, meaning that the convergence is not guaranteed. That is, we are not getting the optimal values $(\mathbf{x}^{*}, \lambda^{*},\mu^{*})$ that maximize the lower bound and minimize the upper bound in each iteration. Instead, we are optimizing the dual problem by a SA algorithm and the master problem by QA, so that none of these methods guarantees the optimal solution to the combinatorial optimization problem.
\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{Figures/QASAProtocol.pdf} 
\caption{QA-SA protocol scheme. See the main text for details on this protocol.}
\label{fig:QA_SAProtocol}
\end{figure}
\begin{enumerate}
    \item Set an initial feasible configuration to the primal problem $\mathbf{x}$.
    \item Solve the dual problem by SA,
\begin{maxi!}[2]
	{\lambda, \mu}{q(\lambda, \mu)}{}{}{\left[q: \mathbb{R}^{m+p} \rightarrow \mathbb{R}\right]}
	\addConstraint{\mu}{\geq \mathbf{0}}{}
	\addConstraint{(\lambda, \mu)}{}{\in \{\lambda, \mu \,\mid q(\lambda, \mu)\quad \textrm{Bounded} \}}.
\end{maxi!}
Notice that the parameters $\lambda$ and $\mu$ do not have to be the optimal parameters. SA does not guarantee to obtain the optimal solution of the dual problem.
    \item Update the master problem with $\{\lambda, \mu\}$ 
    \begin{equation}
        q(\lambda,\mu) = \min_{\mathbf{x}} \mathcal{L}(\mathbf{x}, \lambda, \mu).
    \end{equation}
     QA does not guarantee to obtain the optimal solution $\mathbf{x}^{*}$ of the master problem.
    \item Apply the selection criterion to keep or discard the current configuration.
    \item If the stopping criterion is satisfied, then the protocol outputs the solution. Otherwise, insert the values $\mathbf{x}$ of step 3 into step 2 and repeat until step 4.
\end{enumerate}



